{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve, reformat, clean and store data of the Covid-19 pandemic\n",
    "\n",
    "Data sources:\n",
    "* John Hopkins University (**JHU**) - Center for System Science and Engineering (CSSE)\n",
    "* Berliner Morgenpost (**BMP**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "%matplotlib inline\n",
    "\n",
    "from collections import namedtuple, OrderedDict\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "import unittest\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (15, 8)\n",
    "pd.options.display.max_rows = 8\n",
    "sns.set()\n",
    "\n",
    "tc = unittest.TestCase('__init__')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving JHU data\n",
    "* Dashboard: https://www.arcgis.com/apps/opsdashboard/index.html#/bda7594740fd40299423467b48e9ecf6\n",
    "* Data: https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data\n",
    "\n",
    "Data is available as git repo, thus transfer is compressed. It is assumed that the `COVID-19` repo is `git clone`'d at the same directory level as this `covid-19_analysis`.\n",
    "```\n",
    "cd ..\n",
    "git clone  https://github.com/CSSEGISandData/COVID-19.git\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_19_jhu_repo = Path('../COVID-19')\n",
    "\n",
    "my_pwd = %pwd\n",
    "%cd -q {covid_19_jhu_repo}\n",
    "!git pull\n",
    "%cd -q {my_pwd}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_confirmed_global_JHU = (covid_19_jhu_repo /\n",
    "  \"csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv\")\n",
    "assert filename_confirmed_global_JHU.exists()\n",
    "\n",
    "confirmed_global_JHU = pd.read_csv(filename_confirmed_global_JHU)\n",
    "print(confirmed_global_JHU.keys()[:5])\n",
    "confirmed_global_JHU.set_index(\"Country/Region\", inplace=True)\n",
    "confirmed_global_JHU.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reformat JHU data\n",
    "\n",
    "We are interested in the contries:\n",
    "* Austria\n",
    "* Germany\n",
    "* France\n",
    "\n",
    "We want the table have the data as coloumn (thus transpose it).\n",
    "\n",
    "And the France data is scattered over the departments, thus we need to collect it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COUNTRIES_SELECTED = [\"Germany\", \"Austria\", \"France\"]\n",
    "\n",
    "date_columns = [c for c in confirmed_global_JHU.columns if c.endswith('/20')]\n",
    "cases_JHU = (confirmed_global_JHU\n",
    "    .loc[confirmed_global_JHU.index.isin(COUNTRIES_SELECTED), date_columns]\n",
    "    .transpose()\n",
    "    .reset_index()\n",
    "    .rename(columns={'index': 'date'})\n",
    ")\n",
    "cases_JHU['date'] = pd.to_datetime(cases_JHU['date'])\n",
    "cases_JHU.set_index('date', inplace=True)\n",
    "print(cases_JHU.tail(1))\n",
    "\n",
    "# there are multiple France, let's sum them to one new France2\n",
    "cases_JHU['France2'] = cases_JHU['France'].sum(axis=1)\n",
    "del cases_JHU['France']\n",
    "_rd = OrderedDict([\n",
    "    ('Germany', 'Germany_JHU'),\n",
    "    ('Austria', 'Austria_JHU'),\n",
    "    ('France2', 'France_JHU'),\n",
    "])\n",
    "cases_JHU.rename(columns=_rd, inplace=True)\n",
    "cases_JHU = cases_JHU.reindex(_rd.values(), axis=1)\n",
    "cases_JHU.tail(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting JHU data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cases_JHU.plot(style='o-', logy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving BMP data\n",
    "\n",
    "Total and recovered data are taken manually from the following URL:\n",
    "* https://interaktiv.morgenpost.de/corona-virus-karte-infektionen-deutschland-weltweit/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_BMP = Path(\"data_raw_BMP.csv\")\n",
    "cases_BMP = pd.read_csv(filename_BMP, index_col=[0], parse_dates=[0])\n",
    "cases_BMP.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    tc.assertEqual(cases_BMP.index[-1], cases_JHU.index[-1])\n",
    "except AssertionError as e:\n",
    "    print(\"ERROR: manually add the missing data to %s\" % filename_BMP)\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating infected\n",
    "    \n",
    "$$I_t = I_{t-1} + \\text{new cases}_t - \\text{new recoveries}_t - \\text{new death}_t$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = cases_BMP['confirmed'] >= 100\n",
    "c_rd = cases_BMP[['confirmed', 'recovered_alive', 'death']].diff().loc[mask]\n",
    "\n",
    "N = len(c_rd)\n",
    "infected = np.zeros(N, dtype='f4')\n",
    "for i in range(N):\n",
    "    # NOTE: due to python wrap around and zero init infected[-1] = 0\n",
    "    infected[i] = infected[i - 1] + c_rd['confirmed'].iloc[i] \\\n",
    "                  - c_rd['recovered_alive'].iloc[i] - c_rd['death'].iloc[i]\n",
    "\n",
    "cases_BMP['infected'] = np.nan\n",
    "cases_BMP.loc[mask, 'infected'] = infected\n",
    "\n",
    "cases_BMP['recovered'] = cases_BMP[['recovered_alive', 'death']].sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting BMP data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_kwargs = dict(style='o-', logy=True, legend=True)\n",
    "ax = cases_BMP.loc[mask, ['confirmed', 'infected']].plot(**_kwargs)\n",
    "for key in c_rd.keys():\n",
    "    c_rd[key].plot(ax=ax, label=key + ' delta', **_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join JHU and BMP data, plot and write to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cases_JHU.join(\n",
    "    cases_BMP[['infected', 'recovered']].rename(\n",
    "        columns={'infected': 'Germany_infected_BMP',\n",
    "                  'recovered': 'Germany_recovered_BMP'}\n",
    "    )\n",
    ")\n",
    "df.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.plot(style='o-', logy=True, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('cases.csv', line_terminator=\"\\r\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
